{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA CLEANING : Handling duplicates, missing values and correcting errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling Missing Data:\n",
    "\n",
    "Load a CSV file into a Pandas DataFrame.\n",
    "Check for missing values using df.isnull().sum().\n",
    "Handle missing data by either filling with mean/median or dropping rows with missing values.\n",
    "\n",
    "Sorting Data:\n",
    "\n",
    "Sort the DataFrame by a single column (e.g., age or name).\n",
    "Sort by multiple columns (e.g., name in descending order and age in ascending order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace or remove special characters in text fields\n",
    "# remove special characters from'name'\n",
    "# pandas\n",
    "df('name') = df('name').str.replace(r'[^\\w\\s]','', regex = True)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " r'[^\\w\\s]': This is a regular expression (regex). Let’s break it down:\n",
    "\n",
    " r'': The r before the quotes indicates a raw string, which means backslashes are treated as literal characters and not escape characters.\n",
    "\n",
    "[^\\w\\s]: This is a character class.\n",
    "\n",
    "\\w matches any word character (equivalent to [a-zA-Z0-9_]).\n",
    "\n",
    "\\s matches any whitespace character (spaces, tabs, etc.).\n",
    "\n",
    "^ inside the brackets negates the character class, so [^\\w\\s] matches any character that is not a word character or whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "--sql\n",
    "SELECT id,\n",
    "REGEXP_REPLACE(name, '[^a-zA-Z0-9\\s]', '', 'g') AS name\n",
    "FROM employees;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize values in column\n",
    "# standardize department names (eg. change Sales to SALES)\n",
    "#pandas\n",
    "df['department'] = df['department'].str.upper()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "--sql\n",
    "UPDATE employees\n",
    "SET department = UPPER(department)\n",
    "WHERE department ='Sales';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to fill missing numerical data\n",
    "#pandas\n",
    "median_salary = df['salary'].median()\n",
    "df['salary'].fillna (median_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing values with averages, medians or estimates\n",
    "# misssing value check (it will list out all the column header with sum of null cell)\n",
    "print('Method 1 :')\n",
    "df.isnull().sum()\n",
    "\n",
    "# take only the only column that have null column(have numbers)\n",
    "var1 = [col for col in df.columns if df[col].isnull().sum()!=0]\n",
    "print(df[var1].isnull().sum()) \n",
    "\n",
    "# create the visualisation for the missing value check\n",
    "print('Method 12 :')\n",
    "import missingno as msno\n",
    "msno.matrix(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flag incomplete records for follow-up\n",
    "df[df['Embarked'].isnull()]\n",
    "# it will print out the list of rows that have 'null' for the Embarked column \n",
    "\n",
    "#  list out alll of the rows that have null value in the row\n",
    "sample_incomplete_rows = df[df.isnull().any(axis=1)].head()\n",
    "sample_incomplete_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s a breakdown of what df.describe() does:\n",
    "\n",
    "Numeric Columns: By default, df.describe() will summarize all numeric columns in the DataFrame. It provides the following statistics:\n",
    "- Count: The number of non-null entries.\n",
    "\n",
    "- Mean: The average of the values.\n",
    "\n",
    "- Std: The standard deviation, which measures the amount of variation or dispersion of the values.\n",
    "\n",
    "- Min: The minimum value.\n",
    "\n",
    "- 25%: The 25th percentile (first quartile), which is the value below which 25% of the data falls.\n",
    "\n",
    "- 50%: The 50th percentile (median), which is the middle value of the data.\n",
    "\n",
    "- 75%: The 75th percentile (third quartile), which is the value below which 75% of the data falls.\n",
    "\n",
    "- Max: The maximum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_all = df.describe(include='all')\n",
    "print(summary_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Survived']==0].describe().T.style.background_gradient(subset=['mean','std','50%','count'], cmap='RdPu')\n",
    "\n",
    "# df[df['Survived'] == 0]: This part filters the DataFrame df to include only the rows where the ‘Survived’ column is equal to 0. Essentially, it selects the data for passengers who did not survive.\n",
    "\n",
    "#.describe(): This method generates descriptive statistics for the filtered DataFrame. It provides statistics like count, mean, standard deviation, min, 25th percentile, median (50%), 75th percentile, and max for each column.\n",
    "\n",
    "# .T: This transposes the DataFrame, swapping rows and columns. After transposition, the statistics (like mean, std, etc.) become the columns, and the original columns of the DataFrame become the rows.\n",
    "\n",
    "# .style.background_gradient(subset=['mean', 'std', '50%', 'count'], cmap='RdPu'): This applies a background gradient to the specified subset of columns (‘mean’, ‘std’, ‘50%’, and ‘count’) using the ‘RdPu’ colormap. The gradient helps visualize the values, with different shades representing different magnitudes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/rasyiqah.rozi/AppData/Local/Microsoft/WindowsApps/python3.11.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "pip install ipykernel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'Survived': [0, 1, 0, 1, 0],\n",
    "    'Age': [22, 38, 26, 35, 28],\n",
    "    'Fare': [7.25, 71.83, 7.92, 53.1, 8.05]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Apply the code\n",
    "styled_df = df[df['Survived'] == 0].describe().T.style.background_gradient(subset=['mean', 'std', '50%', 'count'], cmap='RdPu')\n",
    "\n",
    "# Display the styled DataFrame\n",
    "styled_df\n",
    "\n",
    "# In this example, the DataFrame df contains data about passengers, including whether they survived, their age, and the fare they paid. The code filters out the passengers who did not survive, calculates descriptive statistics for them, transposes the result, and applies a background gradient to the specified columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_counts for Multiple Columns\n",
    "for col in df[['Survived','Sex','Embarked']]:\n",
    "print(df[col].value_counts().to_frame())\n",
    "print(\"****\"*7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count\n",
    "Survived\n",
    "0 547\n",
    "1 340\n",
    "****************************\n",
    "count\n",
    "Sex\n",
    "male 575\n",
    "female 312\n",
    "****************************\n",
    "count\n",
    "Embarked\n",
    "S 642\n",
    "C 167\n",
    "Q 76\n",
    "***************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify unsual entries and incorrect errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify outliers or incorrect values based known standards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To convert Date Strings into a Consistent Date Format\n",
    "# convert join_date into YYYY-MM-DD format:\n",
    "#pandas\n",
    "df['join_date'] = pd.to_datetime(df['join_date'], errors ='coerce')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error = 'coerce' argument in pd.to_datetime() is used to hnadle invalid date entries that cannot be converted to a valid datetime object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to remove extra spaces from text fields\n",
    "# pandas\n",
    "# remove extra space from the name\n",
    "df['name'] = df['name'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "--sql\n",
    "SELECT trim(name) as name from employees;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to convert text to upper case to ensure consistency\n",
    "# pandas\n",
    "df['role'] - df['role'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "--sql\n",
    "SELECT id, name, age, gender, salary, join_date,\n",
    "        UPPER(role) AS role\n",
    "FROM employees;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying and deleting duplicated rows based on key columns\n",
    "# pandas\n",
    "# remove dupliactes based on 'name' and 'age'\n",
    "df.drop_duplicates(subset = ['name','age'], keep = 'first', inplace = True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "--sql\n",
    "-- if the row number more than 1, consider as duplicated row as the id also duplicated\n",
    "WITH CTE AS (\n",
    "    SELECT\n",
    "    id\n",
    "    ,column1\n",
    "    ,column2\n",
    "    ,\n",
    "    ROW_NUMBER() OVER (PARTITION BY column1, column2 ORDER BY id) AS ROW_NUMBER\n",
    "    FROM sales\n",
    ")\n",
    "DELETE FROM sales\n",
    "WHERE id IN (\n",
    "    SELECT id\n",
    "    FROM CTE\n",
    "    WHERE row_num > 1 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "clean_df = df.dropna()\n",
    "\n",
    "# Replace missing values with a default value\n",
    "clean_df = df.fillna(0)\n",
    "\n",
    "# Rename columns\n",
    "clean_df = df.rename(columns={'name': 'full_name'}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA FILTERING : Focusing on speficic segments of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Filtering and Subsetting:\n",
    "\n",
    "Filter the DataFrame based on a condition (e.g., rows where age > 30).\n",
    "Extract specific columns from the DataFrame for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to view the data types every column\n",
    "df1 = df.copy()\n",
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out outliers\n",
    "# investigate outliers to determine if they are valid data points or errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove or flag extreme values that may distort results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATING DATAFRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
    "    'age': [25, 30, 35, 40, 45],\n",
    "    'city': ['New York', 'London', 'Paris', 'Tokyo', 'Sydney']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading data from files\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INDEXING AND SELECTING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a column by name\n",
    "names = df['name']\n",
    "print(names)\n",
    "\n",
    "# Select multiple columns by name\n",
    "subset = df[['name', 'age']]\n",
    "print(subset)\n",
    "\n",
    "# Select rows by index\n",
    "row = df.loc[0]  # Select the first row\n",
    "print(row)\n",
    "\n",
    "# Select rows by condition\n",
    "subdf = df[df['age'] > 30]  # Select rows where age is greater than 30\n",
    "print(subdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA AGGREGATION : Summarizing data(sums,averages, counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Mathematical Operations with Pandas:\n",
    "\n",
    "Perform operations like adding a new column to the DataFrame that contains the square root of an existing column (e.g., age).\n",
    "Convert the result of the mathematical operation to an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean age\n",
    "mean_age = df['age'].mean()\n",
    "print(mean_age)\n",
    "\n",
    "# Group by a column and compute the mean of another column\n",
    "grouped = df.groupby('city')['age'].mean()\n",
    "print(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COLUMN SPLITTING & MERGING : Structing data for ease of analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column splitting\n",
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'FullName': ['John Doe', 'Jane Smith', 'Alice Johnson']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Split the 'FullName' column into 'FirstName' and 'LastName'\n",
    "df[['FirstName', 'LastName']] = df['FullName'].str.split(' ', expand=True)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "         FullName FirstName LastName\n",
    "0        John Doe      John      Doe\n",
    "1      Jane Smith      Jane    Smith\n",
    "2  Alice Johnson     Alice  Johnson\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column merging\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'FirstName': ['John', 'Jane', 'Alice'], 'LastName': ['Doe', 'Smith', 'Johnson']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Merge the 'FirstName' and 'LastName' columns into 'FullName'\n",
    "df['FullName'] = df['FirstName'] + ' ' + df['LastName']\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  FirstName LastName        FullName\n",
    "0      John      Doe        John Doe\n",
    "1      Jane    Smith      Jane Smith\n",
    "2     Alice  Johnson  Alice Johnson\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining both techniques\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'FullName': ['John Doe', 'Jane Smith', 'Alice Johnson']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Split the 'FullName' column\n",
    "df[['FirstName', 'LastName']] = df['FullName'].str.split(' ', expand=True)\n",
    "\n",
    "# Perform some operations (e.g., capitalize last names)\n",
    "df['LastName'] = df['LastName'].str.upper()\n",
    "\n",
    "# Merge the columns back into 'FullName'\n",
    "df['FullName'] = df['FirstName'] + ' ' + df['LastName']\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "         FullName FirstName LastName\n",
    "0        John DOE      John      DOE\n",
    "1      Jane SMITH      Jane    SMITH\n",
    "2  Alice JOHNSON     Alice  JOHNSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling missing data during column splitting\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame with missing values\n",
    "data = {'FullName': ['John Doe', 'Jane Smith', None, 'Alice Johnson', '']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "         FullName\n",
    "0        John Doe\n",
    "1      Jane Smith\n",
    "2            None\n",
    "3  Alice Johnson\n",
    "4                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategy 1 : fill missing values before splitting\n",
    "# Fill missing values with a placeholder\n",
    "df['FullName'].fillna('Unknown Unknown', inplace=True)\n",
    "df['FullName'].replace('', 'Unknown Unknown', inplace=True)\n",
    "\n",
    "# Split the 'FullName' column\n",
    "df[['FirstName', 'LastName']] = df['FullName'].str.split(' ', expand=True)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "         FullName FirstName  LastName\n",
    "0        John Doe      John       Doe\n",
    "1      Jane Smith      Jane     Smith\n",
    "2  Unknown Unknown   Unknown   Unknown\n",
    "3  Alice Johnson     Alice   Johnson\n",
    "4  Unknown Unknown   Unknown   Unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# startegy 2 : handle missing values during spliting\n",
    "# Split the 'FullName' column\n",
    "df[['FirstName', 'LastName']] = df['FullName'].str.split(' ', expand=True)\n",
    "\n",
    "# Fill missing values in the new columns\n",
    "df['FirstName'].fillna('Unknown', inplace=True)\n",
    "df['LastName'].fillna('Unknown', inplace=True)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "         FullName FirstName  LastName\n",
    "0        John Doe      John       Doe\n",
    "1      Jane Smith      Jane     Smith\n",
    "2            None   Unknown   Unknown\n",
    "3  Alice Johnson     Alice   Johnson\n",
    "4                Unknown   Unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategy 3 : use a custom function\n",
    "# Custom function to split names and handle missing values\n",
    "def split_name(full_name):\n",
    "    if pd.isna(full_name) or full_name == '':\n",
    "        return ['Unknown', 'Unknown']\n",
    "    parts = full_name.split(' ', 1)\n",
    "    if len(parts) == 1:\n",
    "        parts.append('Unknown')\n",
    "    return parts\n",
    "\n",
    "# Apply the custom function\n",
    "df[['FirstName', 'LastName']] = df['FullName'].apply(split_name).apply(pd.Series)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "         FullName FirstName  LastName\n",
    "0        John Doe      John       Doe\n",
    "1      Jane Smith      Jane     Smith\n",
    "2            None   Unknown   Unknown\n",
    "3  Alice Johnson     Alice   Johnson\n",
    "4                Unknown   Unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PIVOTING/UNPIVOTING : Reshaping data for better insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivoting\n",
    "Pivoting is the process of transforming data from a long format to a wide format. This is useful when you want to summarize data and make it easier to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'Date': ['2024-01-01', '2024-01-01', '2024-01-02', '2024-01-02'],\n",
    "    'Product': ['A', 'B', 'A', 'B'],\n",
    "    'Sales': [100, 150, 200, 250]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Pivot the DataFrame\n",
    "pivot_df = df.pivot(index='Date', columns='Product', values='Sales')\n",
    "\n",
    "print(pivot_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Product         A    B\n",
    "Date                  \n",
    "2024-01-01  100  150\n",
    "2024-01-02  200  250\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unpivoting (Melting)\n",
    "Unpivoting, or melting, is the process of transforming data from a wide format to a long format. This is useful when you want to normalize your data and make it easier to work with for certain types of analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpivot the DataFrame\n",
    "melted_df = pivot_df.reset_index().melt(id_vars='Date', value_vars=['A', 'B'], var_name='Product', value_name='Sales')\n",
    "\n",
    "print(melted_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "         Date Product  Sales\n",
    "0  2024-01-01       A    100\n",
    "1  2024-01-02       A    200\n",
    "2  2024-01-01       B    150\n",
    "3  2024-01-02       B    250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining Both Techniques\n",
    "\n",
    "You can combine pivoting and unpivoting to reshape your data as needed for different types of analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample DataFrame\n",
    "data = {\n",
    "    'Date': ['2024-01-01', '2024-01-01', '2024-01-02', '2024-01-02'],\n",
    "    'Product': ['A', 'B', 'A', 'B'],\n",
    "    'Sales': [100, 150, 200, 250]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Pivot the DataFrame\n",
    "pivot_df = df.pivot(index='Date', columns='Product', values='Sales')\n",
    "\n",
    "# Unpivot the DataFrame\n",
    "melted_df = pivot_df.reset_index().melt(id_vars='Date', value_vars=['A', 'B'], var_name='Product', value_name='Sales')\n",
    "\n",
    "print(\"Pivoted DataFrame:\")\n",
    "print(pivot_df)\n",
    "\n",
    "print(\"\\nUnpivoted DataFrame:\")\n",
    "print(melted_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivoted DataFrame:\n",
    "Product         A    B\n",
    "Date                  \n",
    "2024-01-01  100  150\n",
    "2024-01-02  200  250\n",
    "\n",
    "Unpivoted DataFrame:\n",
    "         Date Product  Sales\n",
    "0  2024-01-01       A    100\n",
    "1  2024-01-02       A    200\n",
    "2  2024-01-01       B    150\n",
    "3  2024-01-02       B    250\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benefits of Pivoting and Unpivoting\n",
    "\n",
    "- Pivoting: Summarizes data, making it easier to analyze and visualize.\n",
    "\n",
    "- Unpivoting: Normalizes data, making it easier to perform operations like filtering, grouping, and aggregating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data\n",
    "x = [1, 2, 3, 4, 5]\n",
    "y = [10, 20, 25, 30, 40]\n",
    "\n",
    "# Create a line plot\n",
    "plt.plot(x, y)\n",
    "plt.title('Simple Line Plot')\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = pd.DataFrame({\n",
    "    'x': [1, 2, 3, 4, 5],\n",
    "    'y': [10, 20, 25, 30, 40]\n",
    "})\n",
    "\n",
    "# Create a scatter plot with regression line\n",
    "sns.lmplot(x='x', y='y', data=data)\n",
    "plt.title('Scatter Plot with Regression Line')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'Fruit': ['Apples', 'Oranges', 'Bananas', 'Grapes'],\n",
    "    'Amount': [10, 15, 7, 12]\n",
    "}\n",
    "\n",
    "# Create a bar chart\n",
    "fig = px.bar(data, x='Fruit', y='Amount', title='Fruit Sales')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "# Enable output in Jupyter Notebook\n",
    "output_notebook()\n",
    "\n",
    "# Sample data\n",
    "x = [1, 2, 3, 4, 5]\n",
    "y = [10, 20, 25, 30, 40]\n",
    "\n",
    "# Create a line plot\n",
    "p = figure(title=\"Interactive Line Plot\", x_axis_label='X-axis', y_axis_label='Y-axis')\n",
    "p.line(x, y, legend_label='Line', line_width=2)\n",
    "\n",
    "show(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = pd.DataFrame({\n",
    "    'x': [1, 2, 3, 4, 5],\n",
    "    'y': [10, 20, 25, 30, 40]\n",
    "})\n",
    "\n",
    "# Create a scatter plot\n",
    "chart = alt.Chart(data).mark_point().encode(\n",
    "    x='x',\n",
    "    y='y'\n",
    ").properties(\n",
    "    title='Simple Scatter Plot'\n",
    ")\n",
    "\n",
    "chart.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = pd.DataFrame({\n",
    "    'x': [1, 2, 3, 4, 5],\n",
    "    'y': [10, 20, 25, 30, 40]\n",
    "})\n",
    "\n",
    "# Create a scatter plot\n",
    "chart = alt.Chart(data).mark_point().encode(\n",
    "    x='x',\n",
    "    y='y'\n",
    ").properties(\n",
    "    title='Simple Scatter Plot'\n",
    ")\n",
    "\n",
    "chart.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = pd.DataFrame({\n",
    "    'x': [1, 2, 3, 4, 5],\n",
    "    'y': [10, 20, 25, 30, 40]\n",
    "})\n",
    "\n",
    "# Create a scatter plot with customizations\n",
    "sns.set(style='whitegrid')\n",
    "scatter_plot = sns.scatterplot(x='x', y='y', data=data, color='red', s=100, marker='D')\n",
    "scatter_plot.set_title('Customized Scatter Plot', fontsize=14, fontweight='bold')\n",
    "scatter_plot.set_xlabel('X-axis', fontsize=12)\n",
    "scatter_plot.set_ylabel('Y-axis', fontsize=12)\n",
    "plt.xticks(fontsize=10, rotation=45)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = pd.DataFrame({\n",
    "    'x': [1, 2, 3, 4, 5],\n",
    "    'y': [10, 20, 25, 30, 40]\n",
    "})\n",
    "\n",
    "# Set Seaborn style\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Create a customized scatter plot\n",
    "plt.figure(dpi=100)\n",
    "scatter_plot = sns.scatterplot(x='x', y='y', data=data, color='blue', s=100, marker='o')\n",
    "scatter_plot.set_title('Fully Customized Scatter Plot', fontsize=16, fontweight='bold')\n",
    "scatter_plot.set_xlabel('X-axis Label', fontsize=14)\n",
    "scatter_plot.set_ylabel('Y-axis Label', fontsize=14)\n",
    "plt.xticks(fontsize=12, rotation=45)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(True, linestyle='--', linewidth=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional Customization Options\n",
    "1. Colors and Styles\n",
    "Matplotlib: Use the color, linestyle, and marker parameters to customize colors and styles.\n",
    "Seaborn: Use the palette parameter to set color palettes.\n",
    "2. Titles and Labels\n",
    "Matplotlib: Use plt.title(), plt.xlabel(), and plt.ylabel() to set titles and labels.\n",
    "Seaborn: Use the set_title(), set_xlabel(), and set_ylabel() methods.\n",
    "3. Legends\n",
    "Matplotlib: Use plt.legend() to add and customize legends.\n",
    "Seaborn: Legends are automatically added, but you can customize them using the legend parameter.\n",
    "4. Grid and Ticks\n",
    "Matplotlib: Use plt.grid() to add grids and plt.xticks()/plt.yticks() to customize ticks.\n",
    "Seaborn: Grids are part of the style settings, and you can customize ticks using the set_xticks() and set_yticks() methods."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
